---
title: "Introduction Ã  lâ€™analyse de rÃ©seau en littÃ©rature"
author: "Pascal Brissette"
date: 2025-09-10
format:
  html:
    toc: true
    toc-depth: 2
    toc-location: left
    code-fold: true
    code-tools: true
    theme: Yeti
    reference-location: margin
    title-block-banner: true
    self-contained: true
    standalone: true
editor: visual
lang: fr
execute:
  freeze: auto
  echo: true
  warning: false
  message: false
---

```{r, include=FALSE}


install_and_load <- function(packages) {
  for (pkg in packages) {
    if (!pkg %in% rownames(installed.packages())) {
      install.packages(pkg)
    }
    library(pkg, character.only = TRUE)
  }
}

pkgs <- c(
  "data.table",
  "tidyr",
  "stringr",
  "kableExtra",
  "DT",
  "gutenbergr",
  "dplyr",
  "readr",
  "igraph",
  "tokenizers",
  "ggplot2"
)

install_and_load(pkgs)
```

# I. Quâ€™est-ce que lâ€™analyse de rÃ©seau ?

Si je vous demandais quel est le personnage central du dernier roman que vous avez lu, selon le roman en question, la rÃ©ponse pourrait Ãªtre Ã©vidente ou, au contraire, elle pourrait dÃ©pendre de plusieurs facteurs. Quâ€™entend-on par Â«centralÂ»? DÃ©signe-t-on par lÃ  le personnage qui est en relation avec le plus grand nombre dâ€™individus? Celui qui est entourÃ© des personnages qui comptent le plus? Celui par qui transite lâ€™information entre plusieurs communautÃ©s?

Câ€™est le genre de questions que se posent celles et ceux qui sâ€™intÃ©ressent aux rÃ©seaux sociaux. Lâ€™analyse de rÃ©seau permet de regarder autrement les rapports de force et les interactions entre individus (dans le monde rÃ©el) ou personnages (dans le monde fictionnel), sans tenir compte *a priori* de leur statut social, de leur capital Ã©conomique ou de leurs titres (prince, duc, comtesse, etc.). Lâ€™analyse de rÃ©seau prend en considÃ©ration les Ã©changes et interactions concrÃ¨tes qui ont lieu dans le cadre de la fiction. Si, par exemple, un roman a comme titre le nom dâ€™un personnage, on dira spontanÃ©ment quâ€™il sâ€™agit du personnage central du roman. Or lâ€™analyse de rÃ©seau pourrait nous apprendre quâ€™un autre personnage est en rÃ©alitÃ© plus central, si on considÃ¨re les relations quâ€™il entretient avec la somme de ses relations avec les autres personnages, par exemple. En somme, lâ€™analyse de rÃ©seau est un autre outil qui, dans lâ€™arsenal de lâ€™analyste, lui permet de faire apparaÃ®tre des aspects cachÃ©s ou moins apparents de la fiction.

Pour rendre visible cette structure sociale, lâ€™analyse de rÃ©seau propose de traduire lâ€™univers complexe dâ€™une Å“uvre en un objet simple et visuel. La mÃ©thode repose sur deux concepts fondamentaux :

-   Les **sommets** ou **nÅ“uds** (ou *vertices* en anglais) : ce sont les entitÃ©s que nous Ã©tudions. Dans notre cas, il sâ€™agira le plus souvent des **personnages** d'une ou de plusieurs Å“uvres littÃ©rairers.
-   Les **liens** (ou *edges* en anglais) : ce sont les **relations** qui unissent les nÅ“uds. Un lien peut reprÃ©senter diverses choses : des paroles Ã©changÃ©es (conversation), la prÃ©sence de deux individus dans un mÃªme espace, un lien de parentÃ©, une transaction financiÃ¨re, un Ã©change de lettres, etc. Le choix de ce qui constitue un lien tient Ã  la question de recherche, Ã  ce que veut dÃ©couvrir et faire apparaÃ®tre lâ€™analyste.

Lâ€™ensemble de ces nÅ“uds et de ces liens forme ce que lâ€™on appelle un **rÃ©seau**. En dessinant ce rÃ©seau, la Â«toileÂ» abstraite des relations que nous percevons Ã  la lecture devient une carte que lâ€™on peut explorer concrÃ¨tement, un **graphe**.

Une fois cette carte dessinÃ©e, nous pouvons aller au-delÃ  de la simple identification du personnage Â«centralÂ». Lâ€™analyse de rÃ©seau ouvre la porte Ã  une sÃ©rie dâ€™explorations nouvelles :

-   **Cartographier des communautÃ©s :** on peut utiliser des algorithmes pour dÃ©tecter automatiquement les Â«cercles sociauxÂ» ou les factions au sein dâ€™un roman. Les membres qui frÃ©quentent le cÃ©nacle de la rue des Quatre-vents ou ceux qui pratiquent le journalisme, dans *Illusions perdues*, apparaitraient dans un graphe comme des groupes distincts et denses.
-   **Identifier les passeurs :** on peut mesurer lâ€™importance dâ€™un personnage non pas seulement au nombre de ses relations, mais Ã  son rÃ´le de Â«pontÂ» entre des communautÃ©s qui, sans lui, resteraient isolÃ©es.
-   **Suivre la circulation :** on peut modÃ©liser la maniÃ¨re dont une information, une rumeur ou une intrigue se propagerait Ã  travers lâ€™univers fictionnel, en identifiant les chemins les plus courts ou les plus probables.

En somme, lâ€™analyse de rÃ©seau fournit au lecteur aguerri des outils pour explorer la structure sociale (ou gÃ©ographique, ou Ã©conomique, etc.) des fictions, pour passer de lâ€™intuition dâ€™une organisation Ã  sa visualisation et Ã  sa mesure. Pour approfondir la question, nous allons revenir au travail dâ€™un critique qui a popularisÃ© cette approche dans les Ã©tudes littÃ©raires : Franco Moretti.

## **Concepts et questions : discussion autour du texte de Franco Moretti**

Dans son article Â« [Network Theory, Plot Analysis](https://litlab.stanford.edu/projects/network-theory-plot-analysis/) Â», Franco Moretti propose dâ€™utiliser une nouvelle approche pour analyser non pas le style, mais lâ€™intrigue (*plot*) dâ€™Å“uvres littÃ©raires. Son ambition est de dÃ©passer lâ€™analyse textuelle traditionnelle pour **quantifier lâ€™intrigue**, câ€™est-Ã -dire la transformer en un objet mesurable.

### **Du rÃ©cit au modÃ¨le : la construction du rÃ©seau**

La premiÃ¨re Ã©tape de Moretti consiste Ã  Â«choisirÂ» ce qui, dans son analyse de *Hamlet*, constituera les nÅ“uds et les liens :

-   Les **personnages** de lâ€™intrigue seront les **nÅ“uds** (ou sommets, *vertices*) du rÃ©seau.

-   Les **interactions** verbales entre eux seront les **liens** (ou arÃªtes, *edges*) reliant ces nÅ“uds.

Pour Moretti, un lien se crÃ©e entre deux personnages dÃ¨s que des mots sont Ã©changÃ©s entre eux (Â«*some words have passed between them*Â» (p. 3). Câ€™est une maniÃ¨re de faire simple et efficace, mais Moretti est le premier Ã  admettre quâ€™elle est aussi une simplification radicale de la rÃ©alitÃ© de lâ€™Å“uvre. En effet, dans son premier modÃ¨le, une longue conversation de 4000 mots entre Hamlet et Horatio a exactement le mÃªme Â«poidsÂ» quâ€™un ordre de 8 mots de Claudius. De plus, les liens nâ€™ont pas de Â«directionÂ»Â : le modÃ¨le indique *que* deux personnages ont parlÃ©, mais pas *qui* a parlÃ© Ã  *qui*. Lâ€™Å“uvre littÃ©raire est ainsi transformÃ©e en un **modÃ¨le** abstrait.

### **De nouvelles maniÃ¨res de Â«voirÂ» lâ€™intrigue**

MalgrÃ© ses simplifications, ce modÃ¨le permet de rendre visibles des aspects de lâ€™Å“uvre autrement difficiles Ã  saisir.

1.  **Le protagoniste, un centre structurel :** lâ€™analyse de rÃ©seau propose une dÃ©finition du Â«protagonisteÂ» qui nâ€™est pas psychologique (Â«conscienceÂ», Â«intÃ©rioritÃ©Â») mais structurelle : câ€™est le personnage le plus central, Â«celui qui minimise la somme des distances Ã  tous les autres sommetsÂ». Dans *Hamlet*, il sâ€™agit bien de Hamlet, ce qui valide la pertinence du modÃ¨le.

2.  **Les Â«rÃ©gionsÂ» de lâ€™intrigue :** la carte du rÃ©seau rÃ©vÃ¨le des zones. Moretti identifie par exemple une Â«rÃ©gion de la mortÂ» : Ã  lâ€™exception dâ€™Horatio, tous les personnages qui sont connectÃ©s *Ã  la fois* aux deux pÃ´les du conflit (Hamlet et Claudius) sont tuÃ©s Ã  la fin de la piÃ¨ce. Soudain, la cause de la tragÃ©die nâ€™est plus seulement lâ€™intention ou lâ€™action individuelle, mais une sorte de fatalitÃ© structurale liÃ©e Ã  la position du personnage dans le rÃ©seau.

### **La force des Â«liens faiblesÂ» : Horatio et la cohÃ©sion du rÃ©seau**

Lâ€™un des rÃ©sultats les plus surprenants de lâ€™analyse de Moretti vient dâ€™une expÃ©rience de pensÃ©e : que se passe-t-il si lâ€™on retire virtuellement un personnage du rÃ©seau ?

-   Si lâ€™on retire **Claudius**, un personnage trÃ¨s central, le rÃ©seau est peu affectÃ©. La raison ? Claudius appartient au cÅ“ur de la cour, un groupe trÃ¨s dense oÃ¹ tout le monde se connaÃ®t dÃ©jÃ . Les sociologues parlent de *clustering* Ã©levÃ©. Le groupe est rÃ©silient.

-   Si lâ€™on retire **Horatio**, un personnage quantitativement moins important, le rÃ©seau se fracture en plusieurs morceaux isolÃ©s.

Horatio est ce que les thÃ©oriciens des rÃ©seaux appellent un **Â«lien faibleÂ»** (*weak tie*). Il nâ€™appartient pas au cÅ“ur dense de la cour, mais il est le seul **pont** (ou *bridge*) qui relie des communautÃ©s qui, sans lui, ne communiqueraient Ã  peu prÃ¨s pas (la cour, les soldats de la garde, le monde extÃ©rieur reprÃ©sentÃ© par Fortinbras). Son importance nâ€™est pas dans le nombre de ses connexions, mais dans leur nature stratÃ©gique. Il assure la cohÃ©sion de lâ€™ensemble.

> **Question :** connaissez-vous, dans *La ComÃ©die humaine* ou dans dâ€™autres Å“uvres (*Harry Potter*, *Le Seigneur des anneaux*, etc.), des personnages qui, bien que nâ€™Ã©tant pas au centre du pouvoir, sont indispensables parce quâ€™ils connectent des mondes sociaux diffÃ©rents ?

### **De lâ€™image au chiffre : les limites de la visualisation**

Dans son Ã©pilogue, Moretti fait un aveu important. Son projet, qui visait la **quantification**, sâ€™est transformÃ© en une analyse **qualitative** basÃ©e sur lâ€™intuition que lui procuraient les **images** des rÃ©seaux. Il parle du Â«bref bonheurÂ» de cette approche visuelle, avant de se heurter aux statistiques.

Il constate que lorsque les rÃ©seaux deviennent trop grands ou trop complexes (par exemple, en ajoutant le Â«poidsÂ» et la Â«directionÂ» des liens), les images deviennent des Â«boules de poilsÂ» illisibles oÃ¹ lâ€™intuition ne sert plus Ã  rien. Pour analyser rigoureusement la structure, il faut alors passer des images aux concepts et aux mesures chiffrÃ©es : calculer la centralitÃ©, la densitÃ©, le *clustering*, etc.

Ce passage de lâ€™image au chiffre, de lâ€™intuition au calcul, est exactement le chemin que nous allons emprunter dans la deuxiÃ¨me partie de lâ€™atelier. Cependant, avant dâ€™aller plus loin, il est important de faire le point sur le concept de Â«centralitÃ©Â».

### **Mesurer lâ€™importance : les diffÃ©rentes facettes de la centralitÃ©**

Comme nous lâ€™avons vu, la notion de personnage Â«centralÂ» ou Â«importantÂ» nâ€™est pas univoque. Lâ€™analyse de rÃ©seau nous offre lâ€™avantage de formaliser cette intuition en proposant diffÃ©rentes **mesures de centralitÃ©**. Chacune de ces mesures rÃ©pond Ã  une question lÃ©gÃ¨rement diffÃ©rente sur le rÃ´le et lâ€™influence dâ€™un personnage au sein de la structure sociale du roman. Il nâ€™y a pas une seule bonne mesure ; le choix dÃ©pend de ce que lâ€™on cherche Ã  comprendre.

Voici les trois mesures de centralitÃ© les plus couramment utilisÃ©es :

#### **1. La centralitÃ© de degrÃ© (*Degree Centrality*)**

-   **DÃ©finition :** câ€™est la mesure la plus simple. Elle correspond au nombre total de liens directs quâ€™un personnage possÃ¨de.

-   **Type de question :** Â« qui est la personne la plus connectÃ©e ou la plus â€œpopulaireâ€ ? Â»

-   **InterprÃ©tation littÃ©raire :** un personnage avec une haute centralitÃ© de degrÃ© est comme un Â«papillon socialÂ» ; il interagit avec un grand nombre dâ€™autres personnages. Câ€™est une mesure directe de lâ€™activitÃ© et de la visibilitÃ© sociale. Dans lâ€™univers de Balzac, une hÃ´tesse de salon cÃ©lÃ¨bre pourrait avoir une centralitÃ© de degrÃ© trÃ¨s Ã©levÃ©e.

#### **2. La centralitÃ© dâ€™intermÃ©diaritÃ© (*Betweenness Centrality*)**

-   **DÃ©finition :** cette mesure Ã©value le nombre de fois quâ€™un personnage se trouve sur le chemin le plus court entre deux autres personnages qui ne sont pas directement liÃ©s.

-   **Type de question :** Â« qui joue le rÃ´le de â€œpontâ€, de â€œpasseurâ€ ou dâ€™â€œintermÃ©diaireâ€ ? Â»

-   **InterprÃ©tation littÃ©raire :** un personnage avec une haute centralitÃ© dâ€™intermÃ©diaritÃ© contrÃ´le le flux dâ€™informations ou de relations entre diffÃ©rents groupes sociaux. Il est stratÃ©giquement positionnÃ©. Câ€™est le cas typique dâ€™**Horatio** dans *Hamlet*, qui connecte des mondes autrement sÃ©parÃ©s. Dans *La ComÃ©die humaine*, un personnage comme **Vautrin** est un intermÃ©diaire : il met en contact le monde du crime, celui des pensions modestes et celui des ambitions aristocratiques.

#### **3. La centralitÃ© de proximitÃ© (*Closeness Centrality*)**

-   **DÃ©finition :** cette mesure calcule la distance moyenne dâ€™un personnage Ã  *tous* les autres personnages du rÃ©seau. Un personnage avec une haute centralitÃ© de proximitÃ© est, en moyenne, Â«procheÂ» de tout le monde.

-   **Type de question**: quel personnage serait en mesure de transmettre le plus rapidement une nouvelle dans le rÃ©seau?

-   **InterprÃ©tation littÃ©raire :** le personnage nâ€™est pas forcÃ©ment le plus populaire (degrÃ©) ni un pont essentiel (intermÃ©diaritÃ©), mais il est Â«au milieu de lâ€™actionÂ». Il a la capacitÃ© dâ€™entendre rapidement les nouvelles et de les rÃ©pandre efficacement. Un valet de chambre bien placÃ© ou un journaliste Ã  lâ€™affÃ»t comme Ã‰tienne Lousteau pourraient avoir une forte centralitÃ© de proximitÃ©. Dans Hamlet, câ€™est le protagoniste qui possÃ¨de la plus haute centralitÃ© de degrÃ©.

### **Autres mesures de lâ€™analyse de rÃ©seau**

1.  **La densitÃ© du rÃ©seau (*Network Density*)**

-   **DÃ©finition :** la densitÃ© mesure Ã  quel point un rÃ©seau est Â«connectÃ©Â». Elle reprÃ©sente la proportion de liens rÃ©els par rapport Ã  tous les liens qui pourraient potentiellement exister. Câ€™est un **score entre 0 (aucune connexion) et 1 (tous les personnages sont directement liÃ©s les uns aux autres)**.

-   **Type de question :** Â«ce monde social est-il un village soudÃ© oÃ¹ tout le monde se connaÃ®t, ou une mÃ©tropole oÃ¹ les individus sont Ã©trangers les uns aux autres ?Â»

-   **InterprÃ©tation littÃ©raire :** la densitÃ© permet de caractÃ©riser lâ€™atmosphÃ¨re dâ€™un groupe social. Un rÃ©seau trÃ¨s dense suggÃ¨re un monde social clos, voire Ã©touffant, oÃ¹ lâ€™information circule vite et oÃ¹ la pression du groupe est forte. On pourrait sâ€™attendre Ã  ce que la densitÃ© du cercle aristocratique dâ€™AngoulÃªme soit bien plus Ã©levÃ©e que celle du rÃ©seau parisien dans son ensemble, qui est plus vaste et fragmentÃ©. Comme le fait Moretti dans son essai, on peut calculer et observer la densitÃ© de zones seulement, puis les comparer.

2.  **La modularitÃ© (*Modularity*)**

-   **DÃ©finition :** la modularitÃ© est une mesure qui Ã©value la qualitÃ© de la division dâ€™un rÃ©seau en communautÃ©s (ou Â« modules Â»). Un score de modularitÃ© Ã©levÃ© (proche de 1) signifie que le rÃ©seau est clairement et naturellement divisÃ© en clusters denses, dont les membres sont bien plus connectÃ©s entre eux quâ€™avec le reste du rÃ©seau.

-   **Type de question :** Â« ce rÃ©seau est-il un seul grand bloc homogÃ¨ne, ou est-il naturellement divisÃ© en plusieurs sous-groupes distincts et cohÃ©rents ? Â»

-   **InterprÃ©tation littÃ©raire :** la modularitÃ© est lâ€™une des mesures les plus puissantes pour lâ€™analyse littÃ©raire, car elle quantifie notre intuition quâ€™un univers fictionnel est composÃ© de Â«mondesÂ» sociaux distincts. Lâ€™algorithme de dÃ©tection de communautÃ©s de Gephi, qui attribue les couleurs aux clusters, est basÃ© sur cette mesure. Un score de modularitÃ© Ã©levÃ© pour le rÃ©seau des *Illusions perdues* confirme lâ€™analyse de lâ€™univers balzacien : non pas une sociÃ©tÃ© unifiÃ©e, mais une sociÃ©tÃ© fragmentÃ©e en sphÃ¨res (la province, Paris, lâ€™aristocratie, la presse, le CÃ©nacle...) qui possÃ¨dent leurs propres logiques internes.

# **II. Atelier pratique : de lâ€™Å“uvre au rÃ©seau**

Maintenant que nous avons explorÃ© les concepts thÃ©oriques de lâ€™analyse de rÃ©seau et les diffÃ©rentes maniÃ¨res de mesurer la centralitÃ©, il est temps de mettre les mains Ã  la pÃ¢te. La premiÃ¨re Ã©tape, et la plus cruciale, nâ€™est pas technique, mais **conceptuelle**. Elle consiste Ã  dÃ©cider comment nous allons traduire lâ€™univers foisonnant dâ€™une Å“uvre littÃ©raire en un jeu de donnÃ©es structurÃ© â€” un ensemble de nÅ“uds et de liens.

### **Du jeu de donnÃ©es brut aux tables pour Gephi**

Pour lancer notre exploration de la mÃ©thode, nous allons utiliser un jeu de donnÃ©es crÃ©Ã© en 2023 par Hyeon-Ju Jeon et O-Joun Lee, disponible sur [Figshare](#0). Ce jeu de donnÃ©es comprend, pour 79 romans de la *ComÃ©die humaine*, la liste des personnages quâ€™on trouve dans chaque roman. Les nÅ“uds de notre rÃ©seau seront les personnages recensÃ©s par Jeon et Lee. Un personnage nommÃ©, par exemple, Â«RubemprÃ©, Lucien-Chardon deÂ», apparaÃ®t, selon le jeu de donnÃ©es, dans six romans de *La ComÃ©die humaine*, mais comme il sâ€™agit du mÃªme personnage dans ces romans, il sera reprÃ©sentÃ© par un seul nÅ“ud.

> Note: Lucien de RubemprÃ© nâ€™apparaÃ®t pas rÃ©ellement dans 6 romans diffÃ©rents: Jeon et Lee ont comptÃ© comme des romans distincts chacune des trois parties d*â€™Illusions perdues*, parues dâ€™abord, il est vrai, comme des romans autonomes entre 1837 et 1843, puis rÃ©unis en 1843 sous le titre *Illusions perdues* dans le tome VIII de *La ComÃ©die humaine*.

Pour les liens, nous utiliserons la cooccurrence des personnages au sein dâ€™un mÃªme roman. Par exemple, si Lucien et Nathan apparaissent dans un roman, un lien sera Ã©tabli entre les deux sommets les reprÃ©sentant.

> Question: quelles consÃ©quences dÃ©coulent de ce choix? Quelle simplification ce choix suppose-t-il? Rappelez-vous les limitations Ã©voquÃ©es par Franco Moretti dans son analyse de *Hamlet*.

```{r}

# On importe la table initiale dans lâ€™environnement sous la forme dâ€™une data.table
ch <- fread("donnees/ReOccurring_Characters_in_Each_Novel.tsv")

# On modifie le nom de la colonne correspondant Ã  lâ€™Id
setnames(ch, old=c("V1"), new = "Id")

# On supprime une colonne inutile
ch[, `# of Re-Occurring Characters`:=NULL]

# Pour visualiser la table dans le module de visualisation, enlevez le croisillon de la ligne qui suit et exÃ©cutez la commande.
# View(ch)
```

Partant de cette table, il va falloir extraire les noms de chaque liste et compter les paires de cooccurrences pour chaque ligne du tableau.

```{r}

# --- Ã‰tape de Nettoyage ---
# On transforme la colonne 'Characters' en une vraie liste de vecteurs de caractÃ¨res
ch_clean <- ch

# La fonction de nettoyage personnalisÃ©e
parse_character_string <- function(char_string) {
  # 1. On retire les crochets du dÃ©but et de la fin, et lâ€™apostrophe initiale et finale
  clean_string <- str_sub(char_string, 3, -3)
  
  # 2. On scinde la chaÃ®ne de caractÃ¨res en utilisant le bon dÃ©limiteur : "', '"
  characters_vector <- str_split(clean_string, pattern = "', '")[[1]]
  
  return(characters_vector)
}

# On applique cette fonction Ã  toute la colonne
ch_clean$Characters <- lapply(ch$Characters, parse_character_string)

# --- Construction de la table des liens (Edges) ---
edges_list <- list()
for(i in 1:nrow(ch_clean)) {
  characters <- ch_clean$Characters[[i]]
  novel <- ch_clean$Novel[i]
  
  # On sâ€™assure quâ€™il y a au moins deux personnages pour crÃ©er un lien
  if(length(characters) > 1) {
    # CrÃ©er toutes les paires possibles (votre logique, qui est excellente)
    pairs <- combn(sort(characters), 2, simplify = FALSE) # Ajout de sort() pour avoir des paires source-target cohÃ©rentes
    
    # Stocker les paires avec le nom du roman
    edges_list[[i]] <- data.table(
      source = sapply(pairs, `[`, 1),
      target = sapply(pairs, `[`, 2),
      novel = novel
    )
  }
}

edges_dt <- rbindlist(edges_list)

# View(edges_dt)
```

Cette table des liens est redondante. Par exemple, si Rastignac et Vautrin apparaissent ensemble dans trois romans, nous avons trois lignes pour le lien Â« Rastignac-Vautrin Â». Ce que nous voulons, câ€™est un seul lien entre eux, mais un lien proportionnel au nombre dâ€™occurrences. Nous allons donc compter ces occurrences pour en faire le poids du lien. Enfin, nous allons extraire la liste unique des personnages pour crÃ©er notre table des sommets.

```{r}
# Rappel du code de lâ€™Ã©tape prÃ©cÃ©dente (avec la correction et le nouveau nom 'ch')
# Assume que 'ch' est dÃ©jÃ  chargÃ© dans RStudio.

# --- 1. Nettoyage de la colonne 'Characters' ---
parse_character_string <- function(char_string) {
  clean_string <- str_sub(char_string, 3, -3)
  characters_vector <- str_split(clean_string, pattern = "', '")[[1]]
  return(characters_vector)
}

ch_clean <- ch # On travaille sur une copie
ch_clean$Characters <- lapply(ch$Characters, parse_character_string)

# --- 2. CrÃ©ation de la table des liens bruts ---
edges_list <- list()
for(i in 1:nrow(ch_clean)) {
  characters <- ch_clean$Characters[[i]]
  novel <- ch_clean$Novel[i]
  
  if(length(characters) > 1) {
    pairs <- combn(sort(characters), 2, simplify = FALSE)
    edges_list[[i]] <- data.table(
      source = sapply(pairs, `[`, 1),
      target = sapply(pairs, `[`, 2)
    )
  }
}
all_edges <- rbindlist(edges_list)

# --- 3. Finalisation des tables pour Gephi ---

# a) Table des liens pondÃ©rÃ©s (Edges Table)
gephi_edges <- all_edges[, .(Weight = .N), by = .(Source = source, Target = target)]
# On ajoute une colonne 'Type' pour dire Ã  Gephi que les liens sont non dirigÃ©s
gephi_edges[, Type := "Undirected"]


# b) Table des sommets (Nodes Table)
# On extrait la liste unique de tous les personnages
all_characters <- unique(c(gephi_edges$Source, gephi_edges$Target))
gephi_nodes <- data.table(Id = all_characters, Label = all_characters)

# --- 4. Exportation des fichiers CSV ---
# On sauvegarde les fichiers dans le dossier de travail nommÃ© "Gephi"

if(!dir.exists("Gephi")) {dir.create("Gephi")}
fwrite(gephi_nodes, "Gephi/comedie_humaine_nodes.csv")
fwrite(gephi_edges, "Gephi/comedie_humaine_edges.csv")

# View(gephi_nodes)
# View(gephi_edges)
```

Ã€ partir dâ€™ici, nous pouvons utiliser le puissant logiciel Gephi, y importer nos deux tables (`comedie_humaine_nodes.csv`, `comedie_humaine_edges.csv`) pour:

1.  calculer la densitÃ© et la modularitÃ© du rÃ©seau, ainsi que les divers types de centralitÃ© pour chacun des personnages;
2.  reprÃ©senter le rÃ©seau sous forme de graphe.

Le graphe obtenu au terme de la spacialisation, pourrait ressembler Ã  celui-ci:

![](images/CH_reseau_clusters.svg)

### **DeuxiÃ¨me partie : le rÃ©seau des *Illusions perdues***

Dans le premier exercice, nous avons adoptÃ© une vue **macro**. Nous avons survolÃ© *La ComÃ©die humaine* pour cartographier les grandes constellations de personnages qui traversent lâ€™Å“uvre. Pour cela, nous avons utilisÃ© un jeu de donnÃ©es dÃ©jÃ  structurÃ© oÃ¹ le lien Ã©tait simple : deux personnages Ã©taient liÃ©s sâ€™ils apparaissaient dans le mÃªme roman.

Il est temps maintenant de changer dâ€™Ã©chelle et de passer Ã  une vue **mÃ©so**. Nous allons plonger dans un seul roman de *La ComÃ©die humaine*, *Illusions perdues*, et tenter de cartographier son univers social interne.

La diffÃ©rence fondamentale est que nous ne partirons pas dâ€™un tableau tout fait, mais dâ€™un matÃ©riau brut, soit **le texte lui-mÃªme**, rÃ©cupÃ©rÃ© depuis [*Gutenberg Project*](https://www.gutenberg.org/ "Gutenberg Project").

Ce dÃ©tour par le texte brut nous confronte Ã  un dÃ©fi que tout chercheur en humanitÃ©s numÃ©riques rencontre : comment identifier un personnage dans un texte ? Balzac nâ€™Ã©crit pas toujours Â« Madame de Bargeton Â». Il utilisera tour Ã  tour Â« Louise Â», Â« NaÃ¯s Â», ou encore Â« la baronne du ChÃ¢telet Â». Pour le lecteur, câ€™est la mÃªme entitÃ©, mais pour un ordinateur, ce sont trois personnes diffÃ©rentes.

Pour rÃ©soudre ce problÃ¨me, nous allons utiliser un outil essentiel : un **dictionnaire des personnages**. Câ€™est une table de correspondance que jâ€™ai prÃ©parÃ©e et qui, pour chaque personnage, liste les principales **variantes** de son nom et les associe Ã  un **nom canonique** unique.

Lâ€™immense avantage de cette mÃ©thode est que notre dictionnaire contient Ã©galement des informations complÃ©mentaires que nous pourrons exploiter dans lâ€™exploration du rÃ©seau : le statut social, le secteur dâ€™activitÃ© ou encore le sexe de chaque personnage. Une fois dans Gephi, nous pourrons poser des questions comme : Â« Les nobles parlent-ils surtout entre eux ? Â», Â« Quels personnages font le pont entre le monde de lâ€™aristocratie et celui du journalisme ? Â».

Pour cette analyse, nous devons aussi redÃ©finir ce quâ€™est un Â« lien Â». Si le lien nâ€™est plus la coprÃ©sence dans un roman, quelle est sa nouvelle dÃ©finition ? Nous ferons un choix mÃ©thodologique courant : **deux personnages seront considÃ©rÃ©s comme liÃ©s sâ€™ils sont mentionnÃ©s dans le mÃªme paragraphe**. Nous aurions pu prendre la phrase comme fenÃªtre de texte, ou encore un nombre de mots fixe (ex.: 100 mots). Le paragraphe reprÃ©sente une unitÃ© de scÃ¨ne ou de pensÃ©e cohÃ©rente, rendant la coprÃ©sence de personnages significative. PrÃ©cisions quâ€™il sâ€™agit dâ€™un choix pÃ©dagogique et pratique orientÃ©e vers lâ€™exploration plus que la dÃ©monstration.

Notre projet sera donc de plonger avec R dans le texte des *Illusions perdues*, dâ€™y dÃ©tecter les personnages grÃ¢ce Ã  notre dictionnaire, de construire le rÃ©seau de leurs interactions paragraphe par paragraphe et, enfin, dâ€™exporter le tout pour lâ€™analyser dans Gephi.

Voyons maintenant comment nous pouvons traduire cette idÃ©e en code.

## Chargement du texte du roman

Vous nâ€™avez pas besoin de comprendre dans le dÃ©tail le code suivant. Ce quâ€™il fait est dÃ©crit ligne par ligne Ã  lâ€™intÃ©rieur du bloc.

```{r load-text}

# 1. Chargement du texte depuis Gutenberg
# Lâ€™objet `text_gutenberg` est un tibble avec les colonnes `gutenberg_id` et `text`.
text_gutenberg <- gutenberg_download("54723", mirror = "http://aleph.gutenberg.org")

# 2. Nettoyage : Suppression de lâ€™en-tÃªte et du pied de page de Gutenberg
# On identifie les lignes de dÃ©but et de fin du contenu rÃ©el.
start_line <- which(str_detect(text_gutenberg$text, "A MONSIEUR VICTOR HUGO."))
end_line <- which(str_detect(text_gutenberg$text, "FIN DU HUITIÃˆME VOLUME."))

# On ne garde que le corps du texte.
text_body <- text_gutenberg  |> 
  slice(start_line:end_line)

# 3. Reconstitution des paragraphes
corpus_paragraphes <- text_body |>
  
  # On crÃ©e une colonne qui indique si une ligne est une rupture de paragraphe (vide ou NA).
  mutate(is_break = (is.na(text) | text == "")) |>
  
  # Lâ€™astuce : `cumsum` crÃ©e un identifiant de groupe qui change Ã  chaque nouvelle rupture.
  mutate(para_id = cumsum(is_break)) |>
  
  # On retire les lignes de rupture elles-mÃªmes.
  filter(!is_break) |>
  
  # On groupe par notre nouvel identifiant de paragraphe.
  group_by(para_id) |>
  
  # On colle toutes les lignes dâ€™un mÃªme groupe en un seul texte, sÃ©parÃ©es par un espace.
  summarize(paragraph_text = paste(text, collapse = " ")) |>
  
  # On extrait la colonne de texte pour obtenir notre vecteur final.
  pull(paragraph_text)

# 4. VÃ©rification
cat("Nombre de paragraphes dÃ©tectÃ©s :", length(corpus_paragraphes), "\n")
cat("\n--- AperÃ§u du paragraphe 50 ---\n")
print(corpus_paragraphes[50])
cat("\n--- AperÃ§u du paragraphe 100 ---\n")
print(corpus_paragraphes[100])
```

## Chargement du dictionnaire des personnages

Nous chargeons maintenant dans lâ€™environnement de programmation le dictionnaire des personnages dâ€™*Illusions perdues*.

```{r load-dictionary}
# Chargement du dictionnaire
dict_raw <- read_delim("donnees/dictionnaire-personnages-Illusions2.tsv", 
                       delim = "\t",
                       locale = locale(encoding = "UTF-8"),
                       col_types = cols(.default = "c"))

# Nettoyage et normalisation
dict_personnages <- dict_raw |>  
  filter(!is.na(Nom_canonique), Nom_canonique != "")  |> 
  rename(
    nom_canonique = `Nom_canonique`,
    variantes = Variantes,
    statut = Statut,
    secteur = Secteur,
    sexe = Sexe
  ) |> 
  mutate(
    # Nettoyage des crochets dans les variables catÃ©gorielles
    statut = str_remove_all(statut, "\\[|\\]"),
    secteur = str_remove_all(secteur, "\\[|\\]"),
    sexe = str_remove_all(sexe, "\\[|\\]")
  )

cat("Nombre de personnages dans le dictionnaire :", nrow(dict_personnages))

# AperÃ§u du dictionnaire
dict_personnages |> 
  head(10) |> 
  kable(caption = "AperÃ§u du dictionnaire des personnages")
```

# PrÃ©traitement des donnÃ©es

## Gestion des variantes nominales

Nous avons jusqu'ici importÃ© notre texte ainsi qu'un dictionnaire comprenant, pour chaque entitÃ© (personnage) du roman, les noms qui servent Ã  le dÃ©signer.

Ce que nous allons maintenant faire:

1.  Extraire les variantes proposÃ©es dans le dictionnaire maison;
2.  CrÃ©er une table oÃ¹ chaque variante est associÃ©e Ã  un nom canonique;
3.  VÃ©rifier le rÃ©sultat.

```{r extract-variants}
# Fonction dâ€™extraction des variantes Ã  partir du champ texte
extraire_variantes <- function(chaine) {
  if (is.na(chaine) || chaine == "") return(character(0))
  
  # Nettoyage des crochets et sÃ©paration par virgule
  chaine <- str_remove_all(chaine, "\\[|\\]")
  variantes <- str_split(chaine, ",\\s*")[[1]]
  
  # Suppression des espaces superflus
  variantes <- str_trim(variantes)
  
  # Retirer les variantes vides
  variantes[variantes != ""]
}

# CrÃ©ation du dictionnaire de correspondance
correspondance_variantes <- dict_personnages |>
  rowwise() |>
  mutate(variantes_liste = list(extraire_variantes(variantes))) |>
  ungroup() |>
  select(nom_canonique, variantes_liste) |>
  tidyr::unnest(variantes_liste) |>
  rename(variante = variantes_liste)

# AperÃ§u de la table de correspondance
correspondance_variantes |>
  head(20) |>
  kable(caption = "Exemples de variantes associÃ©es Ã  leur nom canonique")
```

Nous utiliserons cette table dans les prochaines Ã©tapes pour identifier les personnages prÃ©sents dans chaque segment du texte.

# Segmentation du texte

La fonction que nous allons construire dans le bloc suivant permet de segmenter le texte de trois maniÃ¨re diffÃ©rente (au choix de l'analyste): par paragraphe, par phrase, par segments comprenant un nombre de mots fixe, avec la possibilitÃ© de faire se chevaucher les segments.

> ğŸ“Œ Exemple : un segment de 100 mots avec un chevauchement de 20 % signifie que chaque nouveau segment commence 80 mots aprÃ¨s le prÃ©cÃ©dent, partageant ainsi 20 mots avec lui.

## Fonction de segmentation

```{r tokenize-text}
# Chargement du package nÃ©cessaire pour la segmentation avancÃ©e
library(tokenizers)

# --- CrÃ©ation dâ€™une fonction de segmentation ---

segmenter_texte <- function(texte,
                            methode = "paragraphe",
                            taille_segment = 1,
                            chevauchement = 0) {
  # ... (code de la fonction identique Ã  votre version)
  # 1. DÃ©coupage initial du texte en unitÃ©s de base (mots, phrases, paragraphes)
  unites <- switch(methode,
    "mot"        = tokenize_words(texte, lowercase = FALSE, strip_punct = FALSE)[[1]],
    "phrase"     = tokenize_sentences(texte)[[1]],
    "paragraphe" = tokenize_paragraphs(texte)[[1]],
    stop("MÃ©thode de segmentation non valide. Choisissez 'mot', 'phrase' ou 'paragraphe'.")
  )
  
  total_unites <- length(unites)
  if (total_unites == 0) return(character(0))

  # 2. CrÃ©ation des segments en fonction des paramÃ¨tres
  segments <- list()
  pas <- taille_segment - chevauchement
  if (pas <= 0) stop("Le chevauchement doit Ãªtre infÃ©rieur Ã  la taille du segment.")
  
  debut <- 1
  while (debut <= total_unites) {
    fin <- min(debut + taille_segment - 1, total_unites)
    segment_unites <- unites[debut:fin]
    segments <- append(segments, paste(segment_unites, collapse = " "))
    debut <- debut + pas
  }
  
  return(segments)
}

# On recrÃ©e une chaÃ®ne de texte unique Ã  partir de notre vecteur de paragraphes.
# Câ€™est cette chaÃ®ne unique que nous passerons Ã  notre fonction.
corpus_texte_integral <- paste(corpus_paragraphes, collapse = "\n\n")


# MÃ©thode 1 : Par paragraphes (par dÃ©faut)
# `tokenize_paragraphs` va retrouver les `\n\n` que nous avons utilisÃ©s comme "colle".
segments_para <- segmenter_texte(corpus_texte_integral, methode = "paragraphe")
cat("--- Segmentation par 1 paragraphe ---\n")
cat("Nombre de segments de type paragraphe :", length(segments_para), "\n\n")

# MÃ©thode 2 : Par phrases
segments_phrase <- segmenter_texte(corpus_texte_integral, methode = "phrase", taille_segment = 3, chevauchement = 1)
cat("--- Segmentation par 3 phrases (chevauchement de 1) ---\n")
cat("Segment 1 (phrases 1-3) :\n", segments_phrase[[1]], "\n\n")
cat("Segment 2 (phrases 3-5) :\n", segments_phrase[[2]], "\n\n")

```

Dans les prochaines Ã©tapes, nous utiliserons la segmentation par paragraphe pour dÃ©tecter les personnages prÃ©sents et construire la matrice de cooccurrence.

# DÃ©tection des personnages dans les segments

## Objectif

Nous voulons identifier les personnages prÃ©sents dans chaque segment du texte. Pour cela, nous comparons chaque segment avec la liste des variantes de noms, en utilisant une recherche insensible Ã  la casse.

Deux modes de dÃ©tection sont possibles :

-   **PrÃ©sence/Absence** : un personnage est considÃ©rÃ© prÃ©sent sâ€™il est mentionnÃ© au moins une fois.

-   **FrÃ©quence minimale** : un personnage est considÃ©rÃ© prÃ©sent seulement sâ€™il est mentionnÃ© plusieurs fois (paramÃ©trable).

## Fonction de dÃ©tection

```{r extract-cooccurrences}

# --- DÃ©tection des personnages et crÃ©ation des arÃªtes ---

construire_aretes_depuis_segments <- function(segments,
                                              correspondance_variantes,
                                              min_freq_detection = 1) {
  
  # 1. PRÃ‰PARATION : crÃ©ation dâ€™un "super-motif" regex et une table de correspondance rapide.
  # str_escape est une sÃ©curitÃ© pour les noms avec des caractÃ¨res spÃ©ciaux comme lâ€™apostrophe.
  motif_global <- paste0("\\b", stringr::str_escape(correspondance_variantes$variante), "\\b", collapse = "|")
  
  # On crÃ©e un "dictionnaire" R pour une traduction rapide.
  lookup_table <- setNames(correspondance_variantes$nom_canonique, correspondance_variantes$variante)
  
  
  # 2. DÃ‰TECTION : scanner chaque segment.
  # On applique la dÃ©tection Ã  tous les segments dâ€™un coup.
  tous_les_personnages_par_segment <- lapply(segments, function(segment) {
    
    # a) Extraire toutes les variantes trouvÃ©es dans le segment
    variantes_trouvees <- stringr::str_extract_all(segment,
                                                   stringr::regex(motif_global, ignore_case = TRUE))[[1]]
    
    # Si aucun personnage nâ€™est trouvÃ©, on retourne une liste vide.
    if (length(variantes_trouvees) == 0) {
      return(character(0))
    }
    
    # b) Traduire les variantes trouvÃ©es en noms canoniques
    noms_canoniques_bruts <- lookup_table[variantes_trouvees]
    
    # c) Appliquer le filtre de frÃ©quence (si min_freq_detection > 1)
    if (min_freq_detection > 1) {
      comptes <- table(noms_canoniques_bruts)
      personnages_filtres <- names(comptes[comptes >= min_freq_detection])
      return(personnages_filtres)
    } else {
      # Si min_freq = 1, on prend juste les noms uniques.
      return(unique(noms_canoniques_bruts))
    }
  })
  
  # 3. CRÃ‰ATION DES LIENS (ARÃŠTES)
  aretes_liste <- list()
  for (personnages_segment in tous_les_personnages_par_segment) {
    
    # On trie dâ€™abord le vecteur. `sort()` enlÃ¨ve les NA par dÃ©faut.
    # On obtient ainsi la liste propre des personnages valides pour ce segment.
    personnages_tries <- sort(personnages_segment)
    
    # On ne crÃ©e des paires que si la liste, une fois nettoyÃ©e et triÃ©e, 
    # contient encore au moins 2 personnages.
    if (length(personnages_tries) > 1) {
      # On utilise directement le vecteur dÃ©jÃ  triÃ©.
      paires <- combn(personnages_tries, 2, simplify = FALSE)
      aretes_liste <- append(aretes_liste, paires)
    }
  }
  
  # Si aucune arÃªte nâ€™a Ã©tÃ© trouvÃ©e, retourner une table vide
  if (length(aretes_liste) == 0) {
    return(data.table::data.table(Source = character(), Target = character()))
  }
  
  # Conversion en un data.table propre pour la suite
  aretes_dt <- data.table::rbindlist(
    lapply(aretes_liste, function(p) data.table::data.table(Source = p[1], Target = p[2]))
  )
  
  return(aretes_dt)
}

# --- Application ---

# On utilise les paragraphes comme segments (aprÃ¨s nettoyage du texte)
segments_paragraphes <- segmenter_texte(corpus_texte_integral, methode = "paragraphe")

# GÃ©nÃ©ration des arÃªtes (chaque coprÃ©sence dans un paragraphe crÃ©e un lien)
# On garde la valeur par dÃ©faut `min_freq_detection = 1`.
aretes_brutes <- construire_aretes_depuis_segments(segments_paragraphes, correspondance_variantes)

# AperÃ§u des premiÃ¨res arÃªtes gÃ©nÃ©rÃ©es
cat("Nombre total de co-prÃ©sences (arÃªtes brutes) trouvÃ©es :", nrow(aretes_brutes), "\n\n")
print(head(aretes_brutes, 10))
```

### **Ã‰tape finale : agrÃ©gation et exportation pour Gephi**

Nous avons maintenant une longue table `aretes_brutes` oÃ¹ chaque ligne reprÃ©sente une seule coprÃ©sence dans un paragraphe. Si Lucien et Madame de Bargeton sont mentionnÃ©s ensemble dans 10 paragraphes diffÃ©rents, ils apparaissent sur 10 lignes.

Notre objectif est de transformer cette liste en deux fichiers propres pour Gephi :

1.  Une **table de liens (edges)**, oÃ¹ chaque paire de personnages nâ€™apparaÃ®t quâ€™une seule fois, avec une colonne `Weight` (poids) qui indique le nombre de fois oÃ¹ ils sont apparus ensemble.

2.  Une **table de sommets (nodes)**, qui liste chaque personnage unique et lâ€™enrichit avec les mÃ©tadonnÃ©es de notre dictionnaire (`statut`, `secteur`, `sexe`) ainsi quâ€™une mesure de son importance : le degrÃ© (le nombre de personnages diffÃ©rents auxquels il est liÃ©).

#### **1. AgrÃ©gation et pondÃ©ration des liens**

Nous allons compter le nombre dâ€™occurrences de chaque paire `(Source, Target)` pour calculer le poids de leur lien.

```{r adding-weight}
# Chargement des packages nÃ©cessaires pour la suite
library(igraph)

# AgrÃ©gation des arÃªtes brutes
# On groupe par paire de personnages et on compte le nombre de lignes
aretes_ponderees <- aretes_brutes %>%
  group_by(Source, Target) %>%
  summarize(Weight = n(), .groups = 'drop') %>%
  arrange(desc(Weight)) # On trie pour voir les liens les plus forts en premier

# AperÃ§u de la table des liens finale
cat("Nombre de liens uniques (aprÃ¨s agrÃ©gation) :", nrow(aretes_ponderees), "\n\n")
head(aretes_ponderees, 10) %>%
  knitr::kable(caption = "Top 10 des liens les plus forts dans *Illusions perdues*")
```

#### **2. CrÃ©ation de la table des sommets (nodes)**

Maintenant que nous avons nos liens, nous pouvons en extraire la liste exacte des personnages qui font partie du rÃ©seau. Nous allons ensuite y joindre les mÃ©tadonnÃ©es de notre dictionnaire.

```{r adding-other-variables}
# CrÃ©ation du graphe avec le package 'igraph' pour calculer les mÃ©triques
# Câ€™est la mÃ©thode la plus simple et robuste pour calculer le degrÃ©.
g <- graph_from_data_frame(d = aretes_ponderees, directed = FALSE)

# Calcul du degrÃ© (nombre de connexions uniques pour chaque personnage)
degre_nodes <- degree(g)
table_degres <- data.frame(
  Id = names(degre_nodes),
  Degre = as.numeric(degre_nodes)
)

# CrÃ©ation de la table de base des sommets
# On prend la liste des personnages uniques du graphe et on la joint avec les degrÃ©s
table_sommets <- data.frame(Id = V(g)$name) %>%
  left_join(table_degres, by = "Id") %>%
  # On ajoute une colonne Label, que Gephi utilise pour lâ€™affichage
  mutate(Label = Id) %>%
  # On joint les mÃ©tadonnÃ©es de notre dictionnaire de personnages
  left_join(
    select(dict_personnages, nom_canonique, statut, secteur, sexe), 
    by = c("Id" = "nom_canonique")
  ) %>%
  # On rÃ©organise les colonnes pour plus de clartÃ©
  select(Id, Label, Degre, statut, secteur, sexe) %>%
  distinct(Id, .keep_all = TRUE) # SÃ©curitÃ© pour garantir des sommets uniques

# AperÃ§u de la table des sommets finale
head(table_sommets, 10)
```

#### **3. Exportation des fichiers CSV pour Gephi**

Tout est prÃªt ! Il ne nous reste plus quâ€™Ã  Ã©crire nos deux tables dans des fichiers CSV que Gephi pourra importer directement.

```{r exporting-tables}
# CrÃ©ation dâ€™un rÃ©pertoire pour les rÃ©sultats
output_dir <- "Gephi"
if (!dir.exists(output_dir)) {
  dir.create(output_dir)
}

# Renommage de la table des liens pour correspondre aux colonnes Gephi
table_liens_gephi <- aretes_ponderees

# Exportation des deux fichiers
write_csv(table_sommets, file.path(output_dir, "illusions_perdues_nodes.csv"), na = "")
write_csv(table_liens_gephi, file.path(output_dir, "illusions_perdues_edges.csv"))

cat(paste0("Fichiers exportÃ©s avec succÃ¨s dans le rÃ©pertoire '", output_dir, "' :\n"))
cat("- illusions_perdues_nodes.csv (", nrow(table_sommets), " sommets)\n")
cat("- illusions_perdues_edges.csv (", nrow(table_liens_gephi), " liens)\n")
```

Retrouvons-nous maintenant dans Gephi et importons-y nos deux tables. Le graphe obtenu pourrait ressembler Ã  ceci:

![](images/Illusions_perdues_reseau_clusters.svg){width="703"}

# **Pour aller plus loin : adapter le modÃ¨le pour de nouvelles questions**

Lâ€™analyse de rÃ©seau que nous avons menÃ©e offre un premier aperÃ§u de la structure sociale du roman, c'est-Ã -dire des relations entre les personnages. Nous avons suivi en cela le chemin tracÃ© par Franco Moretti. Cela ne veut cependant pas dire que cette approche se limite Ã  l'exploration et Ã  la mesure des structures sociales. Les scientifiques utilisent la mÃ©thode pour Ã©tudier les interactions entre les gÃ¨nes dans une cellule. Dans un autre atelier, nous utiliserons ces mÃªmes concepts pour Ã©tudier les liens entre les mots clÃ©s d'un thÃ¨me. Ainsi, l'analyse de rÃ©seau se prÃ©sente comme un couteau suisse et les seules limites sont celles de la crÃ©ativitÃ© du chercheur!

Pour clore cet atelier, nous allons Ã©voquer, sans les approfondir, deux autres applications possibles de l'analyse de rÃ©seau dans le contexte d'une analyse littÃ©raire.

Nous allons nous concentrer sur la deuxiÃ¨me partie du roman de Balzac, *Un grand homme de province Ã  Paris*. Les deux analyses concernent l'exploration des espaces du Paris balzacien d*'Illusions perdues*.

## **1. RÃ©seau bipartite : cartographier les espaces parisiens**

Le premier modÃ¨le que nous pouvons envisager est un **rÃ©seau bipartite** (ou Ã  deux modes). Avec cette approche, nous dÃ©finissons deux types distincts de sommets qui ne peuvent Ãªtre connectÃ©s quâ€™entre eux.

-   **Type 1 - les personnages** : Lucien de RubemprÃ©, Coralie, Ã‰tienne Lousteau, Daniel dâ€™Arthez, etc.

-   **Type 2 - les lieux intra-parisiens** : des espaces spÃ©cifiques comme `lâ€™OpÃ©ra`, `le thÃ©Ã¢tre du Gymnase`, `le cafÃ© Flicoteaux`, `le bois de Boulogne`, `le domicile de Coralie`, `les bureaux des journaux`, etc.

Le lien se forme lorsquâ€™un personnage est prÃ©sent dans un lieu. Le rÃ©seau qui en rÃ©sulte ne connecte donc jamais deux personnages entre eux, ni deux lieux entre eux, mais tisse une carte des frÃ©quentations (`Personnage <-> Lieu`).

Un tel rÃ©seau permettrait de rÃ©pondre Ã  des questions de sociospatialisaton :

-   **Quels sont les principaux lieux de sociabilitÃ© ouverts,** oÃ¹ se croisent des personnages dâ€™origines diverses ? On peut imaginer que le Palais-Royal serait l'un de ces lieux.

-   **Quels sont les espaces les plus exclusifs ?** Certains salons ou domiciles privÃ©s nâ€™auront de liens quâ€™avec un cercle trÃ¨s restreint de personnages, matÃ©rialisant visuellement lâ€™entre-soi. D'aprÃ¨s vous, quel est l'espace de sociabilitÃ© le plus exclusif du roman? Le salon de la noble marquise d'Espard ou l'appartement du romancier d'Arthez?

## **2. RÃ©seau dirigÃ© : visualiser les flux et les trajectoires narratives**

Une seconde approche consiste Ã  revenir Ã  un rÃ©seau dont les sommets sont de mÃªme nature (univariÃ©), mais dont les liens sont dirigÃ©s. Ce modÃ¨le permet de cartographier non plus la prÃ©sence, mais le mouvement.

-   **Les sommets** : uniquement les **lieux intra-parisiens** (les mÃªmes que prÃ©cÃ©demment).

-   **Les liens** : Ils sont **dirigÃ©s** (`->`) et reprÃ©sentent un dÃ©placement. Un lien est crÃ©Ã© de `Lieu A -> Lieu B` si la narration dit qu'un personnage se dÃ©place du premier lieu vers le second dans une sÃ©quence textuelle rapprochÃ©e (par exemple, dâ€™un paragraphe Ã  lâ€™autre).

Ce rÃ©seau de flux ne nous dit plus qui va oÃ¹, mais rÃ©vÃ¨le la structure dynamique de la ville telle que la narration la construit.

Il devient possible de poser des questions sur la logique des dÃ©placements :

-   **Quelles sont les Â«grandes routesÂ» de la vie parisienne de l'univers balzacien ?** Des liens avec un poids trÃ¨s Ã©levÃ© entre certains lieux montreraient les trajets les plus frÃ©quents, structurant le quotidien des personnages. Ex.: appartement ==\> bureaux des journaux ==\> salon ==\> restaurant.

-   **Quels lieux fonctionnent comme des destinations ou des points de dÃ©part ?** Un lieu avec un fort Â«degrÃ© entrantÂ» (beaucoup de flÃ¨ches pointent vers lui) est une destination majeure (par exemple: lâ€™OpÃ©ra). Un lieu avec un fort Â«degrÃ© sortantÂ» est un point de dÃ©part ou de passage.

Ces deux exemples illustrent un principe important : en analyse de rÃ©seau appliquÃ©e aux textes, la modÃ©lisation nâ€™est pas une simple Ã©tape technique, mais le cÅ“ur mÃªme de l'analyse. Le choix de dÃ©finir ce que sont les sommets et les liens est dÃ©jÃ  un acte dâ€™interprÃ©tation qui oriente lâ€™ensemble de lâ€™analyse et dÃ©termine les dÃ©couvertes quâ€™il sera possible de faire.

### **Un dernier exercice : mettre le rÃ©seau Ã  lâ€™Ã©preuve**

Lâ€™analyse de rÃ©seau ne se limite pas Ã  crÃ©er une Â«photographieÂ» statique dâ€™un texte. Elle peut aussi devenir un terrain dâ€™expÃ©rimentation pour tester des hypothÃ¨ses sur la structure narrative elle-mÃªme. Dans lâ€™article Â«Network Theory, Plot AnalysisÂ» que nous avons lu, Franco Moretti propose un test sur le rÃ©seau de *Hamlet*. Il supprime certains personnages de ses donnÃ©es pour observer lâ€™effet sur le rÃ©seau. Nous pouvons rÃ©pliquer cette expÃ©rience avec nos propres donnÃ©es pour rÃ©pondre Ã  une question sur la structure du roman de Balzac : **le monde social des *Illusions perdues* est-il aussi dÃ©pendant de son protagoniste, Lucien de RubemprÃ© ?** Si nous retirons Lucien du rÃ©seau, celui-ci sâ€™effondrera-t-il, ou fera-t-il preuve de rÃ©silience ?

Voici comment procÃ©der.

#### **1. PrÃ©parer les donnÃ©es amputÃ©es (dans R)**

Retournons Ã  R pour crÃ©er deux nouveaux fichiers CSV, identiques aux prÃ©cÃ©dents, mais desquels Lucien de RubemprÃ© et tous les liens qui lui sont associÃ©s auront Ã©tÃ© supprimÃ©s.

```{r}
# Le nom canonique Ã  supprimer
personnage_a_retirer <- "Lucien"

# Filtrer la table des sommets
sommets_sans_lucien <- table_sommets %>%
  filter(Id != personnage_a_retirer)

# Filtrer la table des liens (edges)
# On retire tous les liens oÃ¹ Lucien est soit la Source, soit la Target.
liens_sans_lucien <- table_liens_gephi %>%
  filter(Source != personnage_a_retirer, Target != personnage_a_retirer)

# Exporter ces nouvelles tables vers le rÃ©pertoire de rÃ©sultats
write_csv(sommets_sans_lucien, file.path(output_dir, "illusions_sans_lucien_nodes.csv"), na = "")
write_csv(liens_sans_lucien, file.path(output_dir, "illusions_sans_lucien_edges.csv"))

cat("Fichiers pour lâ€™exercice 'sans Lucien' crÃ©Ã©s avec succÃ¨s :\n")
cat("- illusions_sans_lucien_nodes.csv (", nrow(sommets_sans_lucien), " sommets)\n")
cat("- illusions_sans_lucien_edges.csv (", nrow(liens_sans_lucien), " liens)\n")

```

#### **2. Observer et interprÃ©ter le rÃ©sultat (dans Gephi)**

Maintenant, ouvrez Gephi et crÃ©ez un **nouvel espace de travail**. Importez vos deux nouveaux fichiers (`illusions_sans_lucien_nodes.csv` et `illusions_sans_lucien_edges.csv`).

Appliquez les mÃªmes paramÃ¨tres de visualisation que prÃ©cÃ©demment (spatialisation ForceAtlas 2, taille des nÅ“uds par degrÃ©, couleur par communautÃ©, etc.) pour pouvoir comparer Ã©quitablement les deux graphes.

Le graphe obtenu pourrait ressembler Ã  ceci:

![](images/Illusions_perdues_sans_Lucien_reseau_clusters.svg)

Observez le rÃ©sultat et tentez de rÃ©pondre Ã  ces questions :

1.  **Fragmentation ou rÃ©silience ?** Le rÃ©seau Ã©clate-t-il en une multitude de fragments isolÃ©s, comme celui dâ€™*Hamlet* lorsque le protagoniste est retirÃ© du rÃ©seau? Ou bien une structure globale et connectÃ©e subsiste-t-elle ?

2.  **Quelles structures survivent ?** Si le rÃ©seau reste dense, observez-le attentivement. Le monde dâ€™AngoulÃªme (autour de David et Ãˆve) et celui de Paris (autour de Coralie, Lousteau, Nathan) forment-ils encore des ensembles cohÃ©rents et, surtout, sont-ils toujours connectÃ©s entre eux ?

3.  **Qui sont les nouveaux centres ?** Qui sont dÃ©sormais les personnages les plus centraux du roman ? Leur identitÃ© (sâ€™agit-il de personnages parisiens, provinciaux, artistes, aristocrates ?) vous donne-t-elle des indices sur la structure sous-jacente de lâ€™Å“uvre ?

4.  **Quel Ã©tait le vÃ©ritable rÃ´le de Lucien ?** Au vu de vos rÃ©sultats, Ã©tait-il le pilier indispensable qui tenait tout lâ€™Ã©difice social, ou fonctionnait-il plutÃ´t comme le Â«pontÂ» le plus visible entre des mondes qui possÃ¨dent leur propre cohÃ©sion interne ?

Ce simple test de suppression, qui ne prend que quelques minutes, transforme le graphe en un outil dâ€™analyse littÃ©raire. Il nous renseigne sur les choix structurels de Balzac et sur la maniÃ¨re dont il a construit son roman, non pas autour dâ€™un seul individu, mais peut-Ãªtre autour de la confrontation de systÃ¨mes sociaux robustes.

# Suggestions de lectures

-   Chen, Newman, FrÃ©dÃ©rique MÃ©lanie & Thierry Poibeau, Â«Â Network Analysis, Plot Theory: Revisiting French Literature through Character NetworksÂ Â», arXiv, 2024. https://doi.org/10.48550/arXiv.2503.13449

-   Â«Â Introduction to Network Visualization with GEPHI \| Martin GrandjeanÂ Â» \[billet de blogue\], en ligne: <https://www.martingrandjean.ch/introduction-to-network-visualization-gephi/>.

-   Lacroix, Michel, Â«LittÃ©rature, analyse de rÃ©seaux et centralitÃ©: esquisse dâ€™une thÃ©orisation du lien social concret en littÃ©ratureÂ», *Recherches sociographiques*, volume 44, no 3, septembre-dÃ©cembre 2003, p. 475-497. <https://www.erudit.org/fr/revues/rs/2003-v44-n3-rs727/008203ar/>

-   Moretti, Franco, Â«Â Network Theory, Plot AnalysisÂ Â» (2011), en ligne: *Literary Lab Pamphlet* \<<https://litlab.stanford.edu/assets/pdf/LiteraryLabPamphlet2.pdf>\>.

-   Â«Â Martin Grandjean \| Digital humanities, Data visualization, Network analysisÂ Â» \[billet de blogue\], en ligne: <https://www.martingrandjean.ch/>.

Gemini-2.5-Pro (Google, 2025-09) a Ã©tÃ© utilisÃ© pour amÃ©liorer ce document (ajout de commentaires de ligne; optimisation du code R; critique de contenu).
